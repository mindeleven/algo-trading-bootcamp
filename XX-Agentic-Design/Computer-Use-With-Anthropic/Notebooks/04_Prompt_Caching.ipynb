{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a132ccc4-f0f7-4585-a757-79f36ebe7976",
   "metadata": {},
   "source": [
    "## Prompt Caching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b04542c-780d-4894-84ac-94ab3b6f7870",
   "metadata": {},
   "source": [
    "*(Coding along with deeplearning.ai's online course [Building toward Computer Use with Anthropic - Learn how an AI Assistant is built to use and accomplish tasks on computers](https://learn.deeplearning.ai/courses/building-toward-computer-use-with-anthropic/lesson/1/introduction) taught by Colt Steele)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed0bc6a-d576-4ce4-8577-86488454d47e",
   "metadata": {},
   "source": [
    "Prompt caching is a technique in large language model (LLM) applications where previously used prompts and their responses are stored and reused, rather than making a new LLM API call for identical or similar prompts. This reduces API costs, improves response times, and decreases computational load. When a new prompt comes in, the system first checks if a matching or similar prompt exists in the cache before sending the request to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a85a4b39-e9f3-47c4-bc6e-a336754da780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't be a fool and sent your api key to github\n"
     ]
    }
   ],
   "source": [
    "# https://learn.deeplearning.ai/courses/building-toward-computer-use-with-anthropic/lesson/6/prompt-caching\n",
    "from anthropic import Anthropic\n",
    "import pandas as pd\n",
    "\n",
    "anthropic_api_key = pd.read_csv(\"~/tmp/anthropic/anthropic-key-1.txt\", sep=\" \", header=None)[0][0]\n",
    "print(\"Don't be a fool and sent your api key to github\")\n",
    "\n",
    "client = Anthropic(api_key=anthropic_api_key)\n",
    "MODEL_NAME=\"claude-3-5-sonnet-20241022\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4251e7-a203-4ae8-8cdc-04d4a7b40d5d",
   "metadata": {},
   "source": [
    "#### __Loading The Book__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc56aca7-98b3-47ed-8d2d-b4d32c0f9989",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../assets/files/frankenstein.txt', 'r') as file:\n",
    "    book_content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd7fcdea-6d0a-47cd-9950-ba87ffdfccfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "438804"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(book_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5693b404-688a-4cd9-ae9f-863000db6367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'by Mary Wollstonecraft (Godwin) Shelley\\n\\n\\n CONTENTS\\n\\n Letter 1\\n Letter 2\\n Letter 3\\n Letter 4\\n Chapter 1\\n Chapter 2\\n Chapter 3\\n Chapter 4\\n Chapter 5\\n Chapter 6\\n Chapter 7\\n Chapter 8\\n Chapter 9\\n Chapter 10\\n Chapter 11\\n Chapter 12\\n Chapter 13\\n Chapter 14\\n Chapter 15\\n Chapter 16\\n Chapter 17\\n Chapter 18\\n Chapter 19\\n Chapter 20\\n Chapter 21\\n Chapter 22\\n Chapter 23\\n Chapter 24\\n\\n\\n\\n\\nLetter 1\\n\\n_To Mrs. Saville, England._\\n\\n\\nSt. Petersburgh, Dec. 11th, 17—.\\n\\n\\nYou will rejoice to hear that no disaster has accompanied the\\ncommencement of an enterprise which you have regarded with such evil\\nforebodings. I arrived here yesterday, and my first task is to assure\\nmy dear sister of my welfare and increasing confidence in the success\\nof my undertaking.\\n\\nI am already far north of London, and as I walk in the streets of\\nPetersburgh, I feel a cold northern breeze play upon my cheeks, which\\nbraces my nerves and fills me with delight. Do you understand this\\nfeeling? This breeze, which has travelled from the regi'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_content[1000:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53adb6a4-7271-461d-970e-7fe4165cc829",
   "metadata": {},
   "source": [
    "### Uncached Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "884a6327-ea9b-4bbc-bd3c-339f6e8dcc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def make_non_cached_api_call():\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    # marking the bounds of the book with xml\n",
    "                    \"text\": \"<book>\" + book_content + \"</book>\"\n",
    "                },\n",
    "                {\n",
    "                    # our actual question in a second message block\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"What happens in chapter 3?\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    start_time = time.time() # time request gets send\n",
    "    response = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=500,\n",
    "        messages=messages,\n",
    "    )\n",
    "    end_time = time.time() # time response is received \n",
    "\n",
    "    return response, end_time - start_time # returning response plus delta of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e67288e1-ccd6-448a-9cb5-fe30a6540288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-cached time: 94.89 seconds\n",
      "\n",
      "Output (non-cached):\n",
      "[TextBlock(citations=None, text=\"In Chapter 3 of Frankenstein, several key events occur:\\n\\n1. Victor Frankenstein, at age 17, prepares to leave for university at Ingolstadt. However, his departure is delayed when his adopted sister Elizabeth falls ill with scarlet fever.\\n\\n2. While caring for Elizabeth, Victor's mother catches the illness. On her deathbed, she expresses her wish for Victor and Elizabeth to marry, and then she dies.\\n\\n3. After his mother's death, Victor eventually departs for Ingolstadt, though he is reluctant to leave his grieving family.\\n\\n4. At the university, Victor meets two professors:\\n- Professor M. Krempe, who dismisses Victor's interest in alchemists like Cornelius Agrippa as outdated and worthless\\n- Professor M. Waldman, who takes a more sympathetic approach and encourages Victor to study modern chemistry and other branches of natural philosophy\\n\\n5. Waldman's influence proves crucial, as his lecture on modern science inspires Victor. The professor speaks about how modern scientists have achieved real power over nature, unlike the empty promises of the ancient alchemists.\\n\\n6. By the end of the chapter, Victor becomes completely devoted to his scientific studies at Ingolstadt, setting the stage for his future experiments in creating life.\\n\\nThis chapter marks an important turning point as Victor transitions from his sheltered home life to his university studies, and we see the beginning of his obsession with natural philosophy and the mysteries of life and death.\", type='text')]\n"
     ]
    }
   ],
   "source": [
    "non_cached_response, non_cached_time = make_non_cached_api_call()\n",
    "print(f\"Non-cached time: {non_cached_time:.2f} seconds\") # time it took to get the response\n",
    "\n",
    "print(\"\\nOutput (non-cached):\") \n",
    "print(non_cached_response.content) # the non cached response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7c83362-a632-45c7-b5a8-facaf392c6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=108438, output_tokens=328)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what intersts us most here is the token usage\n",
    "non_cached_response.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c0f364-1ed5-4da2-85a1-ab7f97c65e6b",
   "metadata": {},
   "source": [
    "### Cached Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9ca470f-a512-4206-b659-80e393604f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cached_api_call():\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"<book>\" + book_content + \"</book>\",\n",
    "                    # adding cache control\n",
    "                    # caches all the input tokens up to this point\n",
    "                    \"cache_control\": {\"type\": \"ephemeral\"}\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"What happens in chapter 5?\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=500,\n",
    "        messages=messages,\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    return response, end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be2858dd-8373-4a68-8779-7b6176470ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(180) # setting a timeout of three minutes \n",
    "# in order not to reach the 40000 tokens per minute limit\n",
    "response1, duration1 = make_cached_api_call()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea6edce9-1a1d-4060-8e05-c35f7a436621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(id='msg_013Vt9xkCmjdK9cp3RgaBg1w', content=[TextBlock(citations=None, text=\"In Chapter 5, Victor Frankenstein finally succeeds in bringing his creation to life. Here are the key events:\\n\\n1. On a dreary night in November, Frankenstein completes his work and brings the creature to life. However, upon seeing his creation's hideous appearance - yellow skin, black lips, watery eyes - he is immediately filled with horror and disgust.\\n\\n2. Unable to endure looking at his creation, Frankenstein flees from his laboratory and tries to find peace in sleep. However, he has terrible nightmares where he sees Elizabeth, his fiancée, turn into the corpse of his dead mother.\\n\\n3. While sleeping, the monster comes to his bedside and tries to communicate, but Frankenstein is terrified and runs away again.\\n\\n4. The next morning, Frankenstein wanders the streets of Ingolstadt in distress. He eventually runs into his friend Henry Clerval, who has just arrived in town.\\n\\n5. When they return to Frankenstein's apartment, he is relieved to find that the monster has fled. However, the stress of creating the monster and his horror at what he has done causes Frankenstein to fall into a nervous fever that lasts several months.\\n\\n6. Clerval nurses Frankenstein back to health during this time. The chapter ends with Frankenstein beginning to recover, though he remains deeply traumatized by what he has created.\\n\\nThis chapter marks a crucial turning point in the novel, as it shows the moment when Frankenstein succeeds in his scientific endeavor but is immediately horrified by what he has created, setting up the central conflict of the rest of the story.\", type='text')], model='claude-3-5-sonnet-20241022', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(cache_creation_input_tokens=108427, cache_read_input_tokens=0, input_tokens=11, output_tokens=360))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea175640-fbb2-4c92-b8f9-142b218a6c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Usage(cache_creation_input_tokens=108427, cache_read_input_tokens=0, input_tokens=11, output_tokens=360)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1.usage # first run, we've been writing to the cache, no reading here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "132ec846-3599-4540-b889-c5fdfb4ed192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-cached time: 94.92 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f\"Non-cached time: {duration1:.2f} seconds\") # time it took to get the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c17edcfa-4530-438a-8870-ddb4cd910774",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(180) # setting a timeout of three minutes \n",
    "# in order not to reach the 40000 tokens per minute limit\n",
    "response2, duration2 = make_cached_api_call()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11dcbd78-7b02-4f28-8558-a3b3c1374e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(id='msg_01QBG9onCE6tL6kshj6EPY3x', content=[TextBlock(citations=None, text=\"In Chapter 5 of Frankenstein, Victor Frankenstein finally succeeds in bringing his creation to life. However, he is immediately horrified by what he has created. Here are the key events:\\n\\n1. On a dreary November night, Victor finally animates his creature. When it comes to life, he is terrified by its appearance - its yellow skin, watery eyes, black lips, and overall hideous countenance.\\n\\n2. Overwhelmed with horror and disgust, Victor flees from his laboratory and abandons his creation.\\n\\n3. He retreats to his bedchamber, trying to find sleep and forget what he has done, but is plagued by nightmares. In his dreams, he sees Elizabeth, who turns into the corpse of his dead mother.\\n\\n4. When he awakens, he finds the monster at his bedside, reaching out to him and trying to speak. Victor flees again in terror.\\n\\n5. He takes refuge in the courtyard of his building until morning, when he starts walking the streets aimlessly, afraid to return to his apartment and face his creation.\\n\\n6. By chance, he runs into his old friend Henry Clerval, who has just arrived in Ingolstadt. Victor is overjoyed to see him but becomes increasingly agitated.\\n\\n7. When they return to Victor's apartment, he is relieved to find that the monster has fled. However, the stress of the events causes Victor to suffer a nervous breakdown, leading to months of illness during which Clerval nurses him back to health.\\n\\nThis chapter marks the crucial moment when Frankenstein succeeds in his scientific pursuit but immediately regrets and abandons his creation, setting up the central conflict of the novel.\", type='text')], model='claude-3-5-sonnet-20241022', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(cache_creation_input_tokens=108427, cache_read_input_tokens=0, input_tokens=11, output_tokens=372))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c62294a-0e39-4836-80c1-1451943470f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Usage(cache_creation_input_tokens=108427, cache_read_input_tokens=0, input_tokens=11, output_tokens=372)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69d773c8-d35b-4def-a8a0-f1bacffe9fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-cached time: 20.37 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f\"Non-cached time: {duration2:.2f} seconds\") # time it took to get the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68394bd9-5331-40cb-8747-1f0d120a0717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's give it another shot and see if we still have a cache\n",
    "def make_cached_api_call_2():\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"<book>\" + book_content + \"</book>\",\n",
    "                    # adding cache control\n",
    "                    # caches all the input tokens up to this point\n",
    "                    \"cache_control\": {\"type\": \"ephemeral\"}\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"What happens in chapter 1?\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=500,\n",
    "        messages=messages,\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    return response, end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae7a068-034e-4f1d-99ef-720292d38aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(180) # setting a timeout of three minutes \n",
    "# in order not to reach the 40000 tokens per minute limit\n",
    "response3, duration3 = make_cached_api_call_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8084ec-2e85-49ff-b63b-2d5aba0e9f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6036397b-520f-47ec-9ebc-5f9e24b5f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "response3.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947c33ea-3d52-42a2-9d3e-25997bc2e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Non-cached time: {duration3:.2f} seconds\") # time it took to get the response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b48789-c4dd-4f34-aad5-18c4abfea259",
   "metadata": {},
   "source": [
    "#### __Prompt Caching Pricing__\n",
    "\n",
    "* Cache write tokens are 25% more expensive than base input tokens\n",
    "* Cache read tokens are 90% cheaper than base input tokens\n",
    "* Regular input and output tokens are priced at standard rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7a4c28-3614-4ac3-9038-105ca763fc7d",
   "metadata": {},
   "source": [
    "### Multi-Turn Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0782d2f4-daa5-4d2b-8ada-2e6560bf16d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting cache control on the second to last and last user message\n",
    "messages=[\n",
    "    # ...long conversation so far\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Hello, can you tell me more about the solar system\",\n",
    "                \"cache_control\": {\"type\": \"ephemeral\"}\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Certainly! The solar system is the collection of celestial bodies that orbit our Sun. It consists of eight planets, numerous moons, asteroids, comets, and other objects. The planets, in order from closest to farthest from the Sun, are: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune. Each planet has its own unique characteristics and features. Is there a specific aspect of the solar system you'd like to know more about?\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Tell me more about Mars.\",\n",
    "                \"cache_control\": {\"type\": \"ephemeral\"}\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1792e983-8636-4e29-b2a0-3eb3ed213a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting cache control on the second to last and last user message\n",
    "messages=[\n",
    "    # ...long conversation so far\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Hello, can you tell me more about the solar system\",\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Certainly! The solar system is the collection of celestial bodies that orbit our Sun. It consists of eight planets, numerous moons, asteroids, comets, and other objects. The planets, in order from closest to farthest from the Sun, are: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune. Each planet has its own unique characteristics and features. Is there a specific aspect of the solar system you'd like to know more about?\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Tell me more about Mars.\",\n",
    "                \"cache_control\": {\"type\": \"ephemeral\"}\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"I'd love to tell you about Mars.  Mars is....\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"That's really neat.  Tell me about Pluto!\",\n",
    "                \"cache_control\": {\"type\": \"ephemeral\"}\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c252ee-4896-47b1-9a56-97359c813cab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
