{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f850a16-be9d-4151-9c2c-cf8ce009398a",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7415415-1ec4-49c2-8065-e8f320d9b8cd",
   "metadata": {},
   "source": [
    "*(Coding along with the [Anthropic API fundamentals](https://github.com/anthropics/courses/tree/master/anthropic_api_fundamentals) of Anthropic's courses GitHub repo)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43d9dd4-d2a1-4d3c-b7d0-c0024ffe2aef",
   "metadata": {},
   "source": [
    "The goals of this section are to understand how streaming works and to work with stream events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b835bb9-76fd-4e1c-b500-30e4b331006b",
   "metadata": {},
   "source": [
    "## Basis setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d913e369-6dc6-4de9-b80b-5aac69eb8cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't be a fool and sent your api key to github\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/anthropics/courses/blob/master/anthropic_api_fundamentals/05_Streaming.ipynb\n",
    "from anthropic import Anthropic\n",
    "import pandas as pd\n",
    "\n",
    "anthropic_api_key = pd.read_csv(\"~/tmp/anthropic/anthropic-key-1.txt\", sep=\" \", header=None)[0][0]\n",
    "print(\"Don't be a fool and sent your api key to github\")\n",
    "\n",
    "# instantiating the client\n",
    "client = Anthropic(api_key=anthropic_api_key)\n",
    "MODEL_NAME=\"claude-3-5-sonnet-20241022\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff8200e6-be01-4b1c-bd68-f17fe9ea9cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a response back!\n",
      "========================\n",
      "Here's an essay about macaws and clay licks in the Amazon:\n",
      "\n",
      "Macaws and Clay Licks: A Fascinating Natural Phenomenon in the Amazon\n",
      "\n",
      "Deep within the Amazon rainforest, one of nature's most spectacular displays occurs daily at clay licks, where hundreds of brilliant macaws and other parrots gather to consume clay from exposed riverbank walls. This remarkable behavior, known as geophagy, is not only a stunning visual spectacle but also plays a crucial role in these birds' survival and well-being.\n",
      "\n",
      "Clay licks, or \"colpas\" as they are known locally, are natural clay banks typically found along river edges throughout the Amazon basin, particularly in Peru, Bolivia, and Brazil. These sites attract numerous species of parrots, but it is the large, charismatic macaws that create the most impressive displays. With their vibrant plumage ranging from scarlet red to brilliant blue and yellow, species such as the Scarlet Macaw, Blue-and-yellow Macaw, and Red-and-green Macaw transform these earthen walls into living kaleidoscopes of color.\n",
      "\n",
      "The primary reason these birds consume clay is its ability to neutralize toxic compounds found in their diet. Macaws feed on a variety of seeds, fruits, and nuts, many of which contain naturally occurring toxins that plants produce as defense mechanisms. The clay's high mineral content, particularly sodium and other minerals, helps bind to these toxins and prevent them from being absorbed into the birds' bloodstream. Additionally, the clay provides essential minerals that might be lacking in their regular diet.\n",
      "\n",
      "The daily routine at a clay lick follows a predictable pattern. In the early morning hours, as the sun begins to rise, macaws and other parrots gather in the surrounding trees, filling the air with their raucous calls. They carefully scan the area for potential predators before making their descent to the clay bank. The larger macaws typically dominate the prime spots, while smaller parrot species wait their turn or find space along the edges.\n",
      "\n",
      "These clay licks also serve as important social gathering places for these highly intelligent and social birds. Pairs of macaws, which mate for life, arrive together and maintain close proximity while feeding. Young birds learn essential social behaviors and feeding patterns from their elders, making these sites crucial for the transmission of learned behaviors across generations.\n",
      "\n",
      "The importance of clay licks extends beyond the birds themselves. They have become vital sites for conservation efforts and ecotourism in the Amazon. Many indigenous communities have developed sustainable tourism initiatives around these locations, providing economic alternatives to destructive practices like logging and mining. Researchers also use these sites to monitor population health and movement patterns of various parrot species, contributing valuable data to conservation efforts.\n",
      "\n",
      "However, these essential natural features face various threats. Habitat destruction, illegal logging, and mining activities can destroy or contaminate clay licks. The presence of too many tourists or inappropriate viewing practices can disturb the birds' natural behavior patterns. Climate change also poses a threat, as altered rainfall patterns can affect the chemical composition and accessibility of the clay banks.\n",
      "\n",
      "Conservation organizations and local communities are working together to protect these crucial sites. Measures include establishing protected areas around major clay licks, developing responsible tourism guidelines, and monitoring bird populations. These efforts are essential for preserving not only the clay licks themselves but also the complex ecosystem they support.\n",
      "\n",
      "The phenomenon of macaws at clay licks represents one of the Amazon's many ecological marvels. It demonstrates the intricate relationships between species and their environment, the importance of specific landscape features for wildlife survival, and the potential for conservation through sustainable tourism. As we continue to understand and protect these sites, they remain powerful symbols of the Amazon's biodiversity and the need to preserve it for future generations.\n",
      "\n",
      "The\n"
     ]
    }
   ],
   "source": [
    "# just as a recap, the syntax we've used so far:\n",
    "response = client.messages.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write me an essay about macaws and clay licks in the Amazon\",\n",
    "        }\n",
    "    ],\n",
    "    model=MODEL_NAME,\n",
    "    max_tokens=800,\n",
    "    temperature=0,\n",
    ")\n",
    "print(\"We have a response back!\")\n",
    "print(\"========================\")\n",
    "print(response.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4226f0b-0c56-479c-89fc-018719e83cef",
   "metadata": {},
   "source": [
    "With the approach we just used, we only get content back from the API once all of the content has been generated. Nothing is printed out until the entire response is printed all at once. If we don't want to wait for the entire response to be generated before we get a response, we can use __streaming__. With this approach content is streamed to a user's browser and displayed while the model is generating the response "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae46e1c7-ac4f-4d1d-8e8c-378bb3d05319",
   "metadata": {},
   "source": [
    "### Working with streams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efddfa0-d668-48c7-a125-b417bbe7ca38",
   "metadata": {},
   "source": [
    "To get a streaming response from the API we've to pass `stream=True` as a parameter to `client.messages.create`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a69de37e-61f7-4f6f-9686-396189e3c4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = client.messages.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write me a 3 word sentence, without a preamble.  Just give me 3 words\",\n",
    "        }\n",
    "    ],\n",
    "    model=MODEL_NAME,\n",
    "    max_tokens=100,\n",
    "    temperature=0,\n",
    "    stream=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ee491ee-d2cf-4be2-8d7d-98e05301b874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<anthropic.Stream at 0x11a72a420>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking a look at the stream variable\n",
    "stream # stream object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af22b516-bd1e-4b13-8f27-d8042763d7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RawMessageStartEvent(message=Message(id='msg_01KLchS6G7qG6EDWX5ndAEYz', content=[], model='claude-3-5-sonnet-20241022', role='assistant', stop_reason=None, stop_sequence=None, type='message', usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=30, output_tokens=1)), type='message_start')\n",
      "RawContentBlockStartEvent(content_block=TextBlock(citations=None, text='', type='text'), index=0, type='content_block_start')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text='Dogs', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' chase cats.', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockStopEvent(index=0, type='content_block_stop')\n",
      "RawMessageDeltaEvent(delta=Delta(stop_reason='end_turn', stop_sequence=None), type='message_delta', usage=MessageDeltaUsage(output_tokens=7))\n",
      "RawMessageStopEvent(type='message_stop')\n"
     ]
    }
   ],
   "source": [
    "# the stream object is a generator object that yields individual server-sent events (SSE) as they are received from the API\n",
    "# we need to iterate over the stream object and work with each individual server-sent event\n",
    "# iterating over the stream response:\n",
    "for event in stream:\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41156db2-ed98-40c8-8cf0-82f9fa665c26",
   "metadata": {},
   "source": [
    "#### __Color-coded explanation of the streaming events:__\n",
    "\n",
    "<img src=\"../../assets/images/streaming_events.png\" width=\"70%\" />\n",
    "\n",
    "Each stream contains a series of events in the following order:\n",
    "\n",
    "- __MessageStartEvent__ - A message with empty content\n",
    "- __Series of content blocks__ - Each of which contains:\n",
    "  - A __ContentBlockStartEvent__\n",
    "  - One or more __ContentBlockDeltaEvents__\n",
    "  - A __ContentBlockStopEvent__\n",
    "- One or more __MessageDeltaEvents__ which indicate top-level changes to the final message\n",
    "- A final __MessageStopEvent__\n",
    "\n",
    "#### __Events associated with a single content block:__\n",
    "\n",
    "<img src=\"../../assets/images/content_block_events.png\" width=\"70%\" />\n",
    "\n",
    "As we can see in the diagram, the model-generated content we care about comes from the ContentBlockDeltaEvents. Each of them contains a type set to \"content_block_delta.\" To get the content itself, we need to access the `text` property inside of `delta`.\n",
    "\n",
    "*(Image source: # https://github.com/anthropics/courses/blob/master/anthropic_api_fundamentals/05_Streaming.ipynb)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "984791ac-1b2e-4465-a41d-f1b7fb2fc0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dogs\n",
      " chase cats.\n"
     ]
    }
   ],
   "source": [
    "stream = client.messages.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write me a 3 word sentence, without a preamble.  Just give me 3 words\",\n",
    "        }\n",
    "    ],\n",
    "    model=MODEL_NAME,\n",
    "    max_tokens=100,\n",
    "    temperature=0,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for event in stream:\n",
    "    if event.type == \"content_block_delta\":\n",
    "        print(event.delta.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf99aa7f-361e-499f-a764-df4b98ce7c5e",
   "metadata": {},
   "source": [
    "To format the printed content a bit more nicely, we can make use of two additional arguments that we pass to `print()`:\n",
    "\n",
    "- `end=\"\"`: By default, the print() function adds a newline character (\\n) at the end of the printed text. However, by setting end=\"\", we specify that the printed text should not be followed by a newline character. This means that the next print() statement will continue printing on the same line.\n",
    "- `flush=True`: The flush parameter is set to True to force the output to be immediately written to the console or standard output, without waiting for a newline character or the buffer to be filled. This ensures that the text is displayed in real-time as it is received from the streaming response.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19efa44d-d355-4223-95d8-02c6d685a074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dogs chase cats."
     ]
    }
   ],
   "source": [
    "stream = client.messages.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write me a 3 word sentence, without a preamble.  Just give me 3 words\",\n",
    "        }\n",
    "    ],\n",
    "    model=MODEL_NAME,\n",
    "    max_tokens=100,\n",
    "    temperature=0,\n",
    "    stream=True,\n",
    ")\n",
    "for event in stream:\n",
    "    if event.type == \"content_block_delta\":\n",
    "        print(event.delta.text, flush=True, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37de0de4-b622-4715-83d5-7839efff8462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large Language Models (LLMs) work through several key components and processes. Here's a simplified explanation:\n",
      "\n",
      " Process:ng\n",
      "d on massive amounts of text data from the internet, books, and other sources\n",
      " a process called \"unsupervised learning\"\n",
      " a sequence based on previous wordsnext word in\n",
      "\n",
      " Components:\n",
      " neural network structure that processes text\n",
      " Mechanisms: Allow the model to focus on relevant parts of input text\n",
      " store learned patternsof adjustable values that\n",
      "\n",
      "3. Basic Operation:\n",
      " text input\n",
      " multiple layers of neural networks\n",
      " for appropriate responses\n",
      "d patternstext based on learne\n",
      "\n",
      "4. Key Capabilities:\n",
      " recognition in language\n",
      "- Understanding context\n",
      "- Text generation\n",
      "- Task adaptation\n",
      "\n",
      "5. Limitations:\n",
      "- No true understanding or consciousness\n",
      " incorrect or biased information\n",
      " data cutoff datening\n",
      "-time information\n",
      "\n",
      " the actual technical details are quite complex and involve advanced mathematics and computer science concepts."
     ]
    }
   ],
   "source": [
    "# now for a longer text response\n",
    "stream = client.messages.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How do large language models work?\",\n",
    "        }\n",
    "    ],\n",
    "    model=MODEL_NAME,\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    stream=True,\n",
    ")\n",
    "for event in stream:\n",
    "    if event.type == \"content_block_delta\":\n",
    "        print(event.delta.text, flush=True, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbd1ce68-7ec0-46da-a925-2f31757b00b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RawMessageStartEvent(message=Message(id='msg_01DS5cC9quTM3pstNGwmRvaV', content=[], model='claude-3-5-sonnet-20241022', role='assistant', stop_reason=None, stop_sequence=None, type='message', usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=14, output_tokens=2)), type='message_start')\n",
      "RawContentBlockStartEvent(content_block=TextBlock(citations=None, text='', type='text'), index=0, type='content_block_start')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text='Large Language', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' Models (LLMs) work', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=\" through several key components and processes. Here's a\", type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' simplified explanation:\\n\\n1. Architecture', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=':\\n- LLMs are', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' based on transformer architecture, which uses self-', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text='attention mechanisms\\n- They consist of billions', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' of parameters (weights and biases) arrange', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text='d in neural networks\\n- They', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' process text as sequences of tokens (words or', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' word pieces)\\n\\n2. Training', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=':\\n- Pre-trained on massive amounts of text data from', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' the internet, books, and other sources', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text='\\n- Learn patterns and relationships between', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' words through unsupervised learning', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text='\\n- Use techniques like masked language modeling', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' to predict missing words in sentences\\n\\n3. Key', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' mechanisms:\\n- Attention: Helps', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' the model focus on relevant', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' parts of input text\\n- Context', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' understanding: Can maintain context across long sequences', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text='\\n- Pattern recognition: Identifies linguistic', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' patterns and relationships\\n\\n4. Operation', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=':\\n- Takes text input and converts', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' it to numerical representations (', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text='embeddings)\\n-', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' Processes these through multiple layers of neural networks', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text='\\n- Generates probability distributions for possible next tokens\\n-', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' Converts highest probability outputs back to text\\n\\n5.', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' Limitations:\\n- Can\\'t truly \"understand\" like', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' humans do\\n- May produce', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' plausible-sounding but incorrect information\\n-', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' Limited to training data cutoff date\\n- No', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' real-time internet access or', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' learning capability\\n\\nThis is a high-level', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text=' overview; the actual technical details are much more complex', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockDeltaEvent(delta=TextDelta(text='.', type='text_delta'), index=0, type='content_block_delta')\n",
      "RawContentBlockStopEvent(index=0, type='content_block_stop')\n",
      "RawMessageDeltaEvent(delta=Delta(stop_reason='end_turn', stop_sequence=None), type='message_delta', usage=MessageDeltaUsage(output_tokens=296))\n",
      "RawMessageStopEvent(type='message_stop')\n"
     ]
    }
   ],
   "source": [
    "# once again above example with printing out the whole event\n",
    "stream = client.messages.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How do large language models work?\",\n",
    "        }\n",
    "    ],\n",
    "    model=MODEL_NAME,\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for event in stream:\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2e8eb1a-77a6-4fd2-8bc1-39303592f55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large Language Models (LLMs) work through several key components and processes. Here's a simplified explanation:\n",
      "\n",
      "1. Training Process:\n",
      " LLMs are trained on massive amounts of text data from the internet, books, and other sources\n",
      " patterns in language through a process called \"unsupervised learning\"\n",
      " involves predicting the next word in a sequence based on previous words\n",
      "\n",
      "2. Key Components:\n",
      " Transformer architecture: The underlying neural network structure\n",
      " Attention mechanisms: Help the model focus on relevant parts of input text\n",
      ": Billions of adjustable values that store learned patterns\n",
      "\n",
      "3. Basic Operation:\n",
      " text input\n",
      " layers of neural networkstiple\n",
      " appropriate responsess to generate\n",
      " based on contextikely next words\n",
      "\n",
      ":. Key Capabilities\n",
      "- Pattern recognition in language\n",
      "- Understanding context\n",
      "- Text generation\n",
      "- Task adaptation\n",
      "\n",
      "5. Limitations:\n",
      " true understanding or consciousness\n",
      " incorrect information\n",
      "off dated to training data cut\n",
      "- No real-time information\n",
      "\n",
      " actual technical details are quite complex and involve advanced mathematics and computer science concepts."
     ]
    }
   ],
   "source": [
    "# alternative approach with the same result\n",
    "with client.messages.stream(\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How do large language models work?\",\n",
    "        }\n",
    "    ],\n",
    "    model=MODEL_NAME,\n",
    "    temperature=0,\n",
    ") as stream:\n",
    "  for text in stream.text_stream:\n",
    "      print(text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f319328-ec64-438c-947d-6cc1b7419c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nresponse = client.messages.create(\\n    messages=[\\n        {\\n            \"role\": \"user\",\\n            \"content\": \"How do large language models work?\",\\n        }\\n    ],\\n    model=MODEL_NAME,\\n    max_tokens=1000,\\n    temperature=0,\\n)\\nprint(response.content[0].text)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "response = client.messages.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How do large language models work?\",\n",
    "        }\n",
    "    ],\n",
    "    model=MODEL_NAME,\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    ")\n",
    "print(response.content[0].text)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1981cb-ee5c-47ea-b7dd-1a5c8171fe9b",
   "metadata": {},
   "source": [
    "#### __Accessing information about our token usage:__\n",
    "\n",
    "- `MessageStartEvent` contains our input(prompt) token usage information\n",
    "- `MessageDeltaEvent` contains information on how many output tokens were generated\n",
    "\n",
    "<img src=\"../../assets/images/events_token_usage.png\" width=\"70%\" />\n",
    "\n",
    "*(Image source: # https://github.com/anthropics/courses/blob/master/anthropic_api_fundamentals/05_Streaming.ipynb)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf988421-91c6-45a0-bcfb-0ce863f1bfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MESSAGE START EVENT\n",
      "Input tokens used: 14\n",
      "========================\n",
      " Models (LLMs) like myself work through several key components and processes. Here's a simplified explanation:\n",
      "\n",
      "1. Training Data:\n",
      " LLMs are trained on massive amounts of text data from the internet, books, and other sources\n",
      " language and information about the world\n",
      "\n",
      " Architecture:\n",
      " \"transformer\" architecture\n",
      " This consists of layers of neural networks that process text using attention mechanisms\n",
      " weigh the importance of different words in context\n",
      "\n",
      "3. Process:\n",
      " predicts the next word in a sequence based on previous words\n",
      " to understand patterns, grammar, facts, and reasoning through this process\n",
      "adjustable weights) are fine-tuned during training\n",
      "\n",
      " Capabilities:\n",
      " recognition in language\n",
      " and relationshipsntext\n",
      "like text responses\n",
      "izing informationsynthes\n",
      "\n",
      "5. Limitations:\n",
      " No true understanding or consciousness\n",
      "- Can produce incorrect information\n",
      "- Limited to training data cutoff date\n",
      "- Cannot learn from conversations\n",
      "\n",
      " technical details are quite complex and involve advanced mathematics and computer science concepts.\n",
      "========================\n",
      "MESSAGE DELTA EVENT\n",
      "Output tokens used: 268\n"
     ]
    }
   ],
   "source": [
    "# printing out how many tokens are used in our prompt and how many tokens the model generates:\n",
    "stream = client.messages.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How do large language models work?\",\n",
    "        }\n",
    "    ],\n",
    "    model=MODEL_NAME,\n",
    "    max_tokens=1000,\n",
    "    stream=True,\n",
    ")\n",
    "for event in stream:\n",
    "    if event.type == \"message_start\":\n",
    "        input_tokens = event.message.usage.input_tokens\n",
    "        print(\"MESSAGE START EVENT\", flush=True)\n",
    "        print(f\"Input tokens used: {input_tokens}\", flush=True)\n",
    "        print(\"========================\")\n",
    "    elif event.type == \"content_block_delta\":\n",
    "        print(event.delta.text, flush=True, end=\"\")\n",
    "    elif event.type == \"message_delta\":\n",
    "        output_tokens = event.usage.output_tokens\n",
    "        print(\"\\n========================\", flush=True)\n",
    "        print(\"MESSAGE DELTA EVENT\", flush=True)\n",
    "        print(f\"Output tokens used: {output_tokens}\", flush=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8373c7ad-6a06-4942-8844-4494813efb64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
