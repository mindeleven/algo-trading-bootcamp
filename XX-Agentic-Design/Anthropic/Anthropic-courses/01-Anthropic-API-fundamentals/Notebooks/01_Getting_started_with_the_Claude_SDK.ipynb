{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51c227a2-2cf5-439e-9f4c-fc20dc533021",
   "metadata": {},
   "source": [
    "## Getting started with the Claude SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c888e736-4e03-49f7-9a3a-37e583ddaadc",
   "metadata": {},
   "source": [
    "*(Coding along with the [Anthropic API fundamentals](https://github.com/anthropics/courses/tree/master/anthropic_api_fundamentals) of Anthropic's courses GitHub repo)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6b1a55-8a6d-48cb-ac91-5a8c7f90911f",
   "metadata": {},
   "source": [
    "### Basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d48e3c3-5c64-47bc-ad37-a1701cc2a18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't be a fool and sent your api key to github\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/anthropics/courses/blob/master/anthropic_api_fundamentals/01_getting_started.ipynb\n",
    "from anthropic import Anthropic\n",
    "import pandas as pd\n",
    "\n",
    "anthropic_api_key = pd.read_csv(\"~/tmp/anthropic/anthropic-key-1.txt\", sep=\" \", header=None)[0][0]\n",
    "print(\"Don't be a fool and sent your api key to github\")\n",
    "\n",
    "# instantiating the client\n",
    "client = Anthropic(api_key=anthropic_api_key)\n",
    "MODEL_NAME=\"claude-3-5-sonnet-20241022\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd5158a-d6a1-4803-bcf6-3bce8a1791e6",
   "metadata": {},
   "source": [
    "### Making basic requests with the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "820dfa07-e834-4a37-80be-500588c0200b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a haiku about a pet chicken:\n",
      "\n",
      "Feathers soft as silk\n",
      "Scratching earth for tasty treats\n",
      "My garden friend clucks\n"
     ]
    }
   ],
   "source": [
    "# sending our first request\n",
    "# to send a message and receive a response, we'll use the messages.create() method of the client object\n",
    "response = client.messages.create(\n",
    "    model=MODEL_NAME,\n",
    "    max_tokens=1000,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hi there! Please write me a haiku about a pet chicken\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1a9781d2-0fc4-46af-895c-60af9ffd8781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(id='msg_01YNL1jFUtcmyxpe8u4cL88P', content=[TextBlock(citations=None, text=\"Here's a haiku about a pet chicken:\\n\\nFeathers soft as silk\\nScratching earth for tasty treats\\nMy garden friend clucks\", type='text')], model='claude-3-5-sonnet-20241022', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=20, output_tokens=35))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "25021660-8044-49a7-aa66-5d9954dc5a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one I think is pretty clever:\n",
      "\n",
      "What did the quantum physicist say when he wanted to fight someone?\n",
      "\n",
      "\"Let me atom!\"\n",
      "\n",
      "(Get it? Let me at 'em/atom - plus it plays on physics!) 😄\n",
      "\n",
      "Want to hear another one if that wasn't your style?\n"
     ]
    }
   ],
   "source": [
    "# first exercise, tell me a joke\n",
    "response = client.messages.create(\n",
    "    model=MODEL_NAME,\n",
    "    max_tokens=1000,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hi again! Please tell me a joke but make it creative. Not a lame one.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7f6341-b862-4202-aae0-e75d76846ed6",
   "metadata": {},
   "source": [
    "## Working with messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "270b5c78-f458-43c5-ac1d-a517a122d8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message(id='msg_0186hXBxQiHWKuH8fxbPCVse', content=[TextBlock(citations=None, text=\"The exact recipe for Dr Pepper is a trade secret, but the drink is known to be a blend of 23 different flavors. While the complete list isn't public, some of the commonly believed ingredients include:\\n\\n1. Cherry\\n2. Vanilla\\n3. Amaretto/Almond\\n4. Cola\\n5. Blackberry\\n6. Black Licorice\\n7. Prune\\n8. Plum\\n9. Caramel\\n10. Pepper/Spices\\n\\nThe original recipe was created by pharmacist Charles Alderton in Waco, Texas, in 1885. The unique combination of flavors has made Dr Pepper one of the oldest major soft drink brands in America. The company maintains that the exact formula is kept secure in two separate bank vaults in Dallas, with only a few people knowing the complete recipe.\", type='text')], model='claude-3-5-sonnet-20241022', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=18, output_tokens=189))\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/anthropics/courses/blob/master/anthropic_api_fundamentals/02_messages_format.ipynb\n",
    "# we can use client.messages.create() to send a message to Claude and get a response\n",
    "response = client.messages.create(\n",
    "    model=MODEL_NAME,\n",
    "    max_tokens=1000,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What flavors are used in Dr. Pepper?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4763b6d-492e-408a-8bb8-aff4f033aada",
   "metadata": {},
   "source": [
    "The __messages parameter__ is a crucial part of interacting with the Claude API. It allows you to provide the conversation history and context for Claude to generate a relevant response.\n",
    "```\n",
    "messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What flavors are used in Dr. Pepper?\"}\n",
    "    ]\n",
    "```\n",
    "\n",
    "The messages parameter expects a list of message dictionaries, where each dictionary represents a single message in the conversation. Each message dictionary should have the following keys:\n",
    "\n",
    "`role`: A string indicating the role of the message sender. It can be either \"user\" (for messages sent by the user) or \"assistant\" (for messages sent by Claude).\n",
    "`content`: A string or list of content dictionaries representing the actual content of the message. If a string is provided, it will be treated as a single text content block. If a list of content dictionaries is provided, each dictionary should have a \"type\" (e.g., \"text\" or \"image\") and the corresponding content.\n",
    "\n",
    "Example of a messages list with a single user message:\n",
    "```\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hello Claude! How are you today?\"}\n",
    "]\n",
    "```\n",
    "\n",
    "Example with multiple messages representing a conversation:\n",
    "```\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hello Claude! How are you today?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hello! I'm doing well, thank you. How can I assist you today?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you tell me a fun fact about ferrets?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Sure! Did you know that excited ferrets make a clucking vocalization known as 'dooking'?\"},\n",
    "]\n",
    "```\n",
    "\n",
    "__Messages always alternate between user and assistant.__\n",
    "\n",
    "*(Source: [https://github.com/anthropics/courses/blob/master/anthropic_api_fundamentals/02_messages_format.ipynb](https://github.com/anthropics/courses/blob/master/anthropic_api_fundamentals/02_messages_format.ipynb))*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cd22a3-56b2-40ee-b9ab-22780eacd6b3",
   "metadata": {},
   "source": [
    "### Inspecting the message response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d4f9efee-c3d2-40d5-a074-5be5812df385",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.messages.create(\n",
    "    model=MODEL_NAME,\n",
    "    max_tokens=1000,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Translate hello to French. Respond with a single word\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "39b6b7b3-4b82-4b19-9bef-19a137bb8d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(id='msg_014gaZapntFTEFUdBMmaWkNH', content=[TextBlock(citations=None, text='bonjour', type='text')], model='claude-3-5-sonnet-20241022', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=19, output_tokens=6))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the response that we get back\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5925a5d-a001-4592-8f5b-b5aebfa49eef",
   "metadata": {},
   "source": [
    "The response that we get back is a `Message` object that contains a handful of properties:\n",
    "\n",
    "```\n",
    "Message(\n",
    "    id='msg_013ZuJA9PQ12z4B2LXwPns6A',\n",
    "    content=[TextBlock(citations=None, text='Bonjour', type='text')],\n",
    "    model='claude-3-5-sonnet-20241022',\n",
    "    role='assistant',\n",
    "    stop_reason='end_turn',\n",
    "    stop_sequence=None,\n",
    "    type='message',\n",
    "    usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=19, output_tokens=7)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "38ec2feb-2fa6-477d-a1e9-7e96902fe399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bonjour\n"
     ]
    }
   ],
   "source": [
    "# accessing the actual text content of the model's response\n",
    "print(response.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe3514b-e666-4b7f-a71c-a05c305cd99e",
   "metadata": {},
   "source": [
    "#### __A closer look at the `Message object`:__\n",
    "\n",
    "- `id` - a unique object identifier\n",
    "- `type` - The object type, which will always be \"message\"\n",
    "- `role` - The conversational role of the generated message. This will always be \"assistant\".\n",
    "- `model` - The model that handled the request and generated the response\n",
    "- `stop_reason` - The reason the model stopped generating. We'll learn more about this later.\n",
    "- `stop_sequence` - We'll learn more about this shortly.\n",
    "- `usage` - information on billing and rate-limit usage. Contains information on:\n",
    "   - `input_tokens` - The number of input tokens that were used.\n",
    "   - `output_tokens` - The number of output tokens that were used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544d3e56-0f88-4476-b992-e47845286d55",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d7b99731-5659-4663-b3f8-58dd6ff834c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(word, language):\n",
    "    response = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=1000,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Translate {word} to {language}. Respond with a single word.\".format(word=word, language=language)}\n",
    "        ]\n",
    "    )\n",
    "    return response.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "37ff279c-90ce-4751-8902-82b3f2f64801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfortunately, I don't see any message to translate. Could you please provide the text you'd like me to translate to German?\n"
     ]
    }
   ],
   "source": [
    "print(translate('message', 'German'))\n",
    "# confusing the LLM: \"Please provide the message you want me to translate to German.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8bd81c32-5b5d-4853-bd19-58ade1464697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huhn\n"
     ]
    }
   ],
   "source": [
    "print(translate('chicken', 'German'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "02f6bf27-d8c4-4cc8-a2d5-ea3068b48416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cane\n"
     ]
    }
   ],
   "source": [
    "print(translate('dog', 'Italian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aec629e6-9a34-4708-8145-0ca6bb086a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kedi\n"
     ]
    }
   ],
   "source": [
    "print(translate('cat', 'Turkish'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0237b52f-7928-42be-a3cc-6a8950ab2fd8",
   "metadata": {},
   "source": [
    "### Messages list use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53db5878-593b-4d5f-90c8-08196fb7a9ac",
   "metadata": {},
   "source": [
    "#### __Putting words in Claude's mouth__\n",
    "\n",
    "We can supply an assistant message that Claude will use when generating output. Just don't forget: The list of `messages` must start with a user message and messages must alternate between `user` and `assistant`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0953d16f-3247-4cb1-b6cb-77406f71ea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want Claude to write me a haiku that starts with the first line, \"calming mountain air\"\n",
    "# we provide a conversation history as a message object\n",
    "messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"Generate a beautiful haiku\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"calming mountain air\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e211f4d5-bdef-4150-be56-d87f64a89cca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "whispers through the bamboo trees\n",
      "tranquil symphony\n"
     ]
    }
   ],
   "source": [
    "response = client.messages.create(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=500,\n",
    "    messages=messages\n",
    ")\n",
    "print(response.content[0].text) # you've to add calming mountain air as a first line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9186eecf-a542-4f23-8066-247fe99da8ab",
   "metadata": {},
   "source": [
    "### Few-shot prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8ea7eb-75df-403d-b91e-e851078c9dac",
   "metadata": {},
   "source": [
    "The \"few-shot prompting\" strategy involves providing a model with a small number of examples which help guide Claude's generated output. \n",
    "\n",
    "The messages conversation history is an easy way to provide examples to Claude.\n",
    "\n",
    "#### __Example: Analyzing the Sentiment in Tweets__\n",
    "\n",
    "Let's start by simply asking Claude to \"please analyze the sentiment in this tweet: \" and see what sort of output we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ca017a6-9420-41d5-a8e0-f4e393a813fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment expressed in this tweet is positive. The tweet indicates that the person tried a new product (spicy pickles) from the company @PickleCo and enjoyed it, with their \"taste buds doing a happy dance.\" The use of the excited emoji (🌶️🥒) and the hashtags \"#pickleslove\" and \"#spicyfood\" further reinforce the positive sentiment and enthusiasm for the product.\n",
      "\n",
      "Overall, the tweet conveys a very favorable opinion and enjoyment of the new spicy pickles. The person is clearly satisfied with the product and is recommending it to others through their positive review.\n"
     ]
    }
   ],
   "source": [
    "response = client.messages.create(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=500,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"Analyze the sentiment in this tweet: Just tried the new spicy pickles from @PickleCo, and my taste buds are doing a happy dance! 🌶️🥒 #pickleslove #spicyfood\"},\n",
    "    ]\n",
    ")\n",
    "print(response.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7580acbf-7285-4894-ab69-a3d8e3691056",
   "metadata": {},
   "source": [
    "If we prefer that Claude responds with a standardized output format, we can provide Claude with a conversation history that shows exactly how we want it to respond. Here's an output format for a single word (POSITIVE, NEUTRAL, NEGATIVE) response:\n",
    "\n",
    "```\n",
    "messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Unpopular opinion: Pickles are disgusting. Don't @ me\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"NEGATIVE\"},\n",
    "        {\"role\": \"user\", \"content\": \"I think my love for pickles might be getting out of hand. I just bought a pickle-shaped pool float\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"POSITIVE\"},\n",
    "        {\"role\": \"user\", \"content\": \"Seriously why would anyone ever eat a pickle?  Those things are nasty!\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"NEGATIVE\"},\n",
    "        {\"role\": \"user\", \"content\": \"Just tried the new spicy pickles from @PickleCo, and my taste buds are doing a happy dance! 🌶️🥒 #pickleslove #spicyfood\"},\n",
    "    ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "07ee6486-780c-4e86-9b03-1e615ac6135b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "# here's the example with above message format\n",
    "response = client.messages.create(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=500,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Unpopular opinion: Pickles are disgusting. Don't @ me\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"NEGATIVE\"},\n",
    "        {\"role\": \"user\", \"content\": \"I think my love for pickles might be getting out of hand. I just bought a pickle-shaped pool float\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"POSITIVE\"},\n",
    "        {\"role\": \"user\", \"content\": \"Seriously why would anyone ever eat a pickle?  Those things are nasty!\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"NEGATIVE\"},\n",
    "        {\"role\": \"user\", \"content\": \"Just tried the new spicy pickles from @PickleCo, and my taste buds are doing a happy dance! 🌶️🥒 #pickleslove #spicyfood\"},\n",
    "    ]\n",
    ")\n",
    "print(response.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca9aa1c-55f0-4159-aead-d52f5fd9d7c3",
   "metadata": {},
   "source": [
    "### Exercise: Build a Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5252e9-8029-4274-a8ad-9588a3e0dfa3",
   "metadata": {},
   "source": [
    "Build a simple multi-turn command-line chatbot script. \n",
    "\n",
    "The messages format lends itself to building chat-based applications. To build a chat-bot with Claude, it's as simple as:\n",
    "\n",
    "1. Keep a list to store the conversation history\n",
    "2. Ask a user for a message using input() and add the user input to the messages list\n",
    "3. Send the message history to Claude\n",
    "4. Print out Claude's response to the user\n",
    "5. Add Claude's assistant response to the history\n",
    "6. Go back to step 2 and repeat! (use a loop and provide a way for users to quit!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2e713663-286d-4fc1-ba63-0bbc66c0d047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Hi Claude!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hello! How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  What date is it?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Unfortunately, I don't have access to the current date. As an AI assistant without direct access to calendar information, I don't have a way to provide the exact date. I can only respond based on the information and capabilities I've been given by my creators at Anthropic. Is there something else I can try to help with instead?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Can you tell me till which date you've been trained?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: I do not have specific information about the cutoff date of my training data. As an AI system, I don't have direct access to details about my own training process or the data used. I was created by Anthropic, but I'm not privy to the specifics of when my training was completed or what the most recent data I was trained on was. I can only respond based on the knowledge and capabilities I've been given, without being able to reference an exact training cutoff date. I apologize that I can't provide a more specific answer to your question.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Please don't apologize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: No problem, I understand. As an AI assistant, I don't have perfect information about the details of my own training and capabilities. I'm happy to try my best to assist you within the limits of what I'm able to do. Please feel free to ask me any other questions, and I'll do my best to help or clarify what I can and cannot do. My aim is to be as useful as possible, so no need to apologize.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  What do you know about Monero?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Monero is a privacy-focused cryptocurrency that was launched in 2014. Some key things to know about Monero:\n",
      "\n",
      "- It is designed to be a decentralized, secure, and untraceable digital currency. Monero uses cryptography to obfuscate the origins, amounts, and destinations of transactions.\n",
      "\n",
      "- Monero utilizes ring signatures, stealth addresses, and other techniques to hide the identities and transaction details of its users. This makes it difficult to trace Monero transactions.\n",
      "\n",
      "- It is often associated with the desire for financial privacy and has been adopted by some individuals and organizations seeking to transact without third-party oversight.\n",
      "\n",
      "- Monero operates on a proof-of-work consensus mechanism, which allows it to be mined using CPUs and GPUs, rather than specialized ASIC hardware.\n",
      "\n",
      "- The Monero project is open-source and developed by a community of volunteers. There is no central authority controlling or issuing Monero.\n",
      "\n",
      "- While the privacy features of Monero have drawn interest, it has also raised concerns that the cryptocurrency could potentially be used for illicit activities like money laundering or tax evasion.\n",
      "\n",
      "Does this help summarize some of the key aspects of Monero that I'm aware of? Let me know if you have any other questions.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Do you think money laundering or tax evasion are reasons why Monero should be forbidden?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: That's an interesting and complex question. I don't have personal opinions on whether cryptocurrencies like Monero should be forbidden or not. As an AI assistant, I don't make moral judgments or policy recommendations. \n",
      "\n",
      "While Monero's privacy features could potentially enable illicit activities, many argue that the right to financial privacy is important and that Monero has legitimate use cases beyond criminal activity. There are valid debates around balancing privacy rights, law enforcement needs, and the potential harms of money laundering or tax evasion.\n",
      "\n",
      "Ultimately, decisions about the regulation and legality of technologies like Monero involve weighing various ethical, legal, and economic considerations. I don't have a stance on what the right policy approach should be. I can only provide factual information about Monero's technical features and how it's been discussed, rather than making normative claims. Does this help explain my perspective on this topic? Let me know if you have any other questions.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Okay thank you. Let's quit here!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Sounds good, I'm happy to wrap up our conversation here. Thank you for the interesting discussion about Monero - I appreciate you engaging with me on this topic. Feel free to reach out if you have any other questions in the future that I can try to assist with. Have a great rest of your day!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User typed `quit`. Conversation ended.\n"
     ]
    }
   ],
   "source": [
    "# Keep a list to store the conversation history\n",
    "conversation_history = []\n",
    "\n",
    "# conversation runs in a loop\n",
    "while True:\n",
    "    # Ask a user for a message using input() and add the user input to the messages list\n",
    "    user_input = input(\"User: \")\n",
    "\n",
    "    # provide a way for user to break the loop\n",
    "    if user_input.lower() == \"quit\":\n",
    "        print(\"User typed `quit`. Conversation ended.\")\n",
    "        break\n",
    "\n",
    "    # Keep a list to store the conversation history\n",
    "    # add the user input to the messages list\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    # Send the message history to Claude\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        messages=conversation_history,\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    # store claude's response in variable\n",
    "    assistant_response = response.content[0].text\n",
    "\n",
    "    # Print out Claude's response to the user\n",
    "    print(f\"Assistant: {assistant_response}\")\n",
    "\n",
    "    # Add Claude's assistant response to the history\n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8080ee-18fa-4627-960a-75c12a3e7aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
